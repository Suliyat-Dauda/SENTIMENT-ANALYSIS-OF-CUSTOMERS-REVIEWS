{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(r'C:\\Users\\Bluechip\\Desktop\\DATA ANALYTICS AND TECHNOLOGIES\\SECOND SEMESTER\\THESIS\\data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010315",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f793a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = data_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values \n",
    "data_set.dropna(subset=['Class Name','Division Name','Department Name'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5389ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Review Text and Title into one\n",
    "data_set['Reviewed_Text'] = data_set['Title'].fillna('') + '! ' + data_set['Review Text'].fillna('')\n",
    "\n",
    "#View last 5 rows \n",
    "data_set.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac05f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.drop(['Title','Review Text','Division Name','Class Name','Positive Feedback Count','Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be6880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914026a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all words into lower case\n",
    "\n",
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].str.lower()\n",
    "\n",
    "\n",
    "data_set[\"Reviewed_Text\"][18:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ed522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand contractions\n",
    "import contractions\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Call function on 'Reviews Text' column\n",
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].apply(expand_contractions)\n",
    "\n",
    "data_set[\"Reviewed_Text\"][18:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].apply(lambda text:remove_stopwords(text))\n",
    "\n",
    "data_set[\"Reviewed_Text\"][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING PUNCTUATION\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].apply(lambda text: remove_punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184765aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING NUMBERS\n",
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].apply(lambda x : re.sub(r'[^a-z]',' ',x))\n",
    "\n",
    "data_set[\"Reviewed_Text\"][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMATIZATION\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[\"Reviewed_Text\"] = data_set[\"Reviewed_Text\"].apply(lambda text: lemmatize_words(text))\n",
    "\n",
    "data_set[\"Reviewed_Text\"][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c09ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a sentiment analyser function for polarity\n",
    "\n",
    "def sentiment(review):\n",
    "    return review.apply(lambda Text: pd.Series(TextBlob(Text).sentiment.polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['polarity'] = sentiment(data_set[\"Reviewed_Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(polarity):\n",
    "    if polarity >= 0.5:\n",
    "        return 'positve'\n",
    "    elif polarity < 0.2:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Polarity_Sentiment'] = data_set['polarity'].apply(get_sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536ad6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = \" \".join(i for i in data_set['Reviewed_Text'])\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"black\").generate(text)\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def freq_words(x, terms=9):\n",
    "    all_words = ' '.join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "    \n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word': list(fdist.keys()), 'count': list(fdist.values())})\n",
    "    \n",
    "    # Selecting the top 'terms' frequent words\n",
    "    d = words_df.nlargest(columns='count', n=terms)\n",
    "    \n",
    "    total = d['count'].sum()  # Total count of selected words\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = sns.barplot(data=d, x=\"word\", y=\"count\")\n",
    "    ax.set(ylabel=\"count\")\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height}\\n({height/total:.1%})',\n",
    "                    xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b572d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words(data_set[\"Reviewed_Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def n_ngram(corpus,n = None,ngram = 1):\n",
    "    vec = CountVectorizer(stop_words = 'english',ngram_range=(ngram,ngram)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus) #Have the count of  all the words for each review\n",
    "    sum_words = bag_of_words.sum(axis =0) #Calculates the count of all the word in the whole review\n",
    "    words_freq = [(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq,key = lambda x:x[1],reverse = True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words= n_ngram(data_set['Reviews Text'], 10,1)\n",
    "data = pd.DataFrame(common_words, columns = ['Reviews_Text' , 'count'])\n",
    "plt.figure(figsize =(10,5))\n",
    "data.groupby('Reviewed_Text').sum()['count'].sort_values(ascending=False).plot(\n",
    "kind='bar', title='Top 10 unigrams in review after removing stop words')\n",
    "\n",
    "total = d['count'].sum()  # Total count of selected words\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "  ax = sns.barplot(data=d, x=\"word\", y=\"count\")\n",
    "    ax.set(ylabel=\"count\")\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height}\\n({height/total:.1%})',\n",
    "                    xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Function to generate n-grams\n",
    "def n_ngram(text_list, n, min_count):\n",
    "    all_ngrams = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for text in text_list:\n",
    "        words = [word for word in text.split() if word.lower() not in stop_words]\n",
    "        ngram_list = list(ngrams(words, n))\n",
    "        all_ngrams.extend(ngram_list)\n",
    "    \n",
    "    ngram_counts = Counter(all_ngrams)\n",
    "    common_ngrams = [(ngram, count) for ngram, count in ngram_counts.items() if count >= min_count]\n",
    "    \n",
    "    return common_ngrams\n",
    "\n",
    "# Get common unigrams with count\n",
    "common_words = n_ngram(data_set['Reviewed_Text'], 1, 1)\n",
    "data = pd.DataFrame(common_words, columns=['Reviewed_Text', 'count'])\n",
    "\n",
    "# Sort by count in descending order\n",
    "data = data.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Plotting the top 10 unigrams\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(data=data.head(10), x=\"Reviewed_Text\", y=\"count\", palette= 'prism_r')\n",
    "ax.set(title='Top 10 words using unigrams', xlabel=\"Words\", ylabel=\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Annotating with percentages\n",
    "total = data['count'].sum()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}\\n',#({height/total:.1%})',\n",
    "                xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordclouds(text, title): \n",
    "  stop_words = list(STOPWORDS)\n",
    "  wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords = stop_words).generate(str(text))\n",
    "  plt.figure()\n",
    "  plt.title(title)\n",
    "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = data_set['Reviewed_Text'][data_set[\"Polarity_Sentiment\"] == 'positive']\n",
    "negative_reviews = data_set['Reviewed_Text'][data_set[\"Polarity_Sentiment\"] == 'negative']\n",
    "neutral_reviews = data_set['Reviewed_Text'][data_set[\"Polarity_Sentiment\"] == 'neutral']\n",
    "\n",
    "create_wordclouds(positive_reviews, \"Positive - Review Wordcloud\")\n",
    "create_wordclouds(negative_reviews, \"Negative -  Review Wordcloud\")\n",
    "create_wordclouds(neutral_reviews, \"Neutral -  Review Wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37720d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "\n",
    "def get_sentiments(text_review):\n",
    "    doc = nlp(text_review)\n",
    "    sentiment = doc._.blob.polarity\n",
    "    sentiment = round(sentiment, 2)\n",
    "    \n",
    "    if sentiment > 0.5:\n",
    "        label = \"POSITIVE\"\n",
    "    elif sentiment < 0.2:\n",
    "        label = \"NEGATIVE\"\n",
    "    else:\n",
    "        label = \"NEUTRAL\"\n",
    "        \n",
    "    positive_words = []\n",
    "    negative_words = []\n",
    "    neutral_words =  []\n",
    "    adjective_words = []\n",
    "\n",
    "    for word in doc._.blob.sentiment_assessments.assessments:\n",
    "        if word[1] > 0:\n",
    "            positive_words.append(word[0][0])\n",
    "        elif word[1] < 0:\n",
    "            negative_words.append(word[0][0])\n",
    "        else:\n",
    "            neutral_words.append(word[0][0])\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adjective_words.append(token)\n",
    "\n",
    "    return label, sentiment, positive_words, negative_words, neutral_words, adjective_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[\"spacy_analysis\"] = [get_sentiments(rev) for rev in data_set[\"Reviewed_Text\"]]\n",
    "data_set[\"spacy_sentiment\"] = [i[0] for i in data_set[\"spacy_analysis\"]]\n",
    "data_set[\"spacy_score\"] = [i[1] for i in data_set[\"spacy_analysis\"]]\n",
    "data_set[\"spacy_pos\"] = [i[2] for i in data_set[\"spacy_analysis\"]]\n",
    "data_set[\"spacy_neg\"] = [i[3] for i in data_set[\"spacy_analysis\"]]\n",
    "data_set[\"spacy_neu\"] = [i[3] for i in data_set[\"spacy_analysis\"]]\n",
    "data_set[\"spacy_adj\"] = [i[4] for i in data_set[\"spacy_analysis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = data_set[\"spacy_pos\"]\n",
    "negative_reviews = data_set[\"spacy_neg\"]\n",
    "neutral_reviews = data_set[\"spacy_neu\"]\n",
    "\n",
    "create_wordclouds(positive_reviews, \"Positive - Review using Spacy\")\n",
    "create_wordclouds(negative_reviews, \"Negative - Review Using Spacy\")\n",
    "create_wordclouds(neutral_reviews, \"Neutral - Review Using Spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac946296",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [18, 26, 36, 46, 56, 66, 76, 86, 96, 99]  # Customize the age groups and bins as per your requirement\n",
    "age_labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66-75', '76-85', '86-95', '96-99']  # Labels for each age group\n",
    "\n",
    "# Categorize age groups using pd.cut()\n",
    "data_set['Age Group'] = pd.cut(data_set['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "age_group_names = {'18-25': 'Genz','26-35': 'Millennium','36-45': 'GenX','46-55': \n",
    "                   'Baby Boomers','56-65': 'Silent Generation','66-75': 'Greatest Generation','76-85': 'Veterans',\n",
    "                    '86-95': 'Centenarians','96-99': 'Centenarians+'}\n",
    "\n",
    "data_set['Age Group Name'] = data_set['Age Group'].map(age_group_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.figure(figsize=(10, 5))\n",
    "ax = sns.countplot(x='Age Group', data=data_set)\n",
    "\n",
    "total = len(data_set)  # Total number of data points\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}\\n({height/total:.1%})',\n",
    "                xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Age Group', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax.set_title('Distribution of Age Groups', fontsize=17)\n",
    "ax.tick_params(labelsize=10)\n",
    "plt.xticks(rotation=40)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "ax = sns.countplot(x='Department Name', data=data_set, palette='twilight_shifted')\n",
    "\n",
    "total = len(data_set)  # Total number of data points\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}\\n({height/total:.2%})',\n",
    "                xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Purchases in Department ', fontsize=15)\n",
    "plt.xlabel('Department Name', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b65ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter positive reviews and drop rows with missing 'Review Text'\n",
    "#positive_reviews = data_set[data_set['Polarity_Sentiment'] == 'positive']#.dropna(subset=['Reviewed_Text'])\n",
    "\n",
    "positive_reviews = data_set[data_set['spacy_sentiment'] == 'NEGATIVE']#.dropna(subset=['Reviewed_Text'])\n",
    "\n",
    "#positive_reviews = data_set[[\"spacy_pos\", \"Reviewed_Text\",\"Age Group\"]]\n",
    "\n",
    "# Create word cloud for different age groups\n",
    "age_groups = data_set['Age Group'].unique()\n",
    "\n",
    "# Function to generate word cloud for positive reviews in each age group\n",
    "def generate_word_cloud_for_age_group(age_group):\n",
    "    text = \" \".join(review for review in positive_reviews[positive_reviews['Age Group'] == age_group]['Reviewed_Text'])\n",
    "    wordcloud = WordCloud(width=800, height=300, background_color='black').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='kaiser')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for Positive Reviews in Age Group: {age_group}')\n",
    "    plt.show()\n",
    "#'antialiased', 'none', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', \n",
    "#'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'blackman'\n",
    "# Generate word cloud for each age group\n",
    "for age_group in age_groups:\n",
    "    generate_word_cloud_for_age_group(age_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f566a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(x='Age Group', hue='Department Name', data=data_set, palette='Set2')\n",
    "\n",
    "# Calculate count and percentage of each department within each age group\n",
    "total_counts = data_set.groupby(['Age Group', 'Department Name']).size().unstack()\n",
    "percentages = total_counts.div(total_counts.sum(axis=1), axis=0) * 100\n",
    "percentages = percentages.round(0)  # Round to nearest whole number\n",
    "\n",
    "# Adjust font settings\n",
    "font = {'size': 17, 'family': 'Franklin Gothic'}\n",
    "plt.title('Distribution of Purchases by Age Group and Department ', fontsize=20, fontdict=font)\n",
    "plt.xlabel('Age Group', fontsize=15, fontdict=font)\n",
    "plt.ylabel('Percentage', fontsize=15, fontdict=font)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set legend title and show legend\n",
    "plt.legend(title='Department')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Display the count and percentage table\n",
    "print(\"Count Table:\")\n",
    "print(total_counts)\n",
    "print(\"\\nPercentage Table:\")\n",
    "print(percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed8fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.countplot(x='Department Name', hue='spacy_sentiment', data=data_set, palette='Set1')\n",
    "\n",
    "total = len(data_set)  # Total number of data points\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}\\n({height/total:.1%})',\n",
    "                xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Sentiment Distribution by Departments', fontsize=20)\n",
    "plt.xlabel('Departments', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7058f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
